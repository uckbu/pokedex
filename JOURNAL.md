<!--
  ===================    !!READ THIS NOTICE!!   ====================
  DO NOT edit this file manually. Your changes WILL BE OVERWRITTEN!
  This journal is auto generated and updated by Hack Club Blueprint.
  To edit this file, please edit your journal entries on Blueprint.
  ==================================================================
-->

This is my journal of the design and building process of **pokedex**.  
You can view this journal in more detail on **Hack Club Blueprint** [here](https://blueprint.hackclub.com/projects/626).


## 10/19/2025 12 AM - Created initial wildlife detector script  

Researched available and easy wildlife detection tools that are widely available, easy to run, and functional on lower-end edge devices (ideally something around the power of a Raspberry Pi 5).

Came to the conclusion that PytorchWildlife would be a sufficient workable solution and began researching how to write code that implements its wildlife detection with a PiCamera.

Wrote a second sample for my Mac to prove that it would be a functional implementation.
Backtracked and ended up running a docker container compiled by the PWL team.

But... unfortunately realized way too late that this only specified ANIMAL, and not the TYPE of animal...
![Screenshot 2025-10-19 at 12.21.12â€¯AM.png](https://blueprint.hackclub.com/user-attachments/blobs/proxy/eyJfcmFpbHMiOnsiZGF0YSI6MzE3OSwicHVyIjoiYmxvYl9pZCJ9fQ==--bd23b7f848db54ad2418307f4fb497a2d5b17ca5/Screenshot%202025-10-19%20at%2012.21.12%E2%80%AFAM.png)

Onto the next idea, I guess. Maybe a 3B VL LLM? I dislike wrappers.. but it could work on a pi with a high system memory, especially since we need some sort of universal animal detection that is very difficult to come by with models.

Ideally I will get a working prototype then train a series of my own YOLO models to move away from the LLM in the future.  

## 10/19/2025 9 PM - Wrote code to reroute image to LLMs  

I wrote a script that uses an LLM (qwen2.5VL:3b for its small size and the fact that it can likely run on a raspberry pi 5) to analyze an image and determine what animal it is. My goat emi aided me in this endeavor.

The script opens a webcam stream with OpenCV, continuously displaying frames while listening for keyboard input. When the c key is detected, the current frame is resized if larger than 1024 pixels on any side, compressed to JPEG with quality 90, and base64-encoded for transmission.


The encoded image is packaged into an Ollama chat request targeting qwen2.5vl:3b, using a concise prompt asking for a single-word animal identification (so that the output can be routed into the answer from the pokedex). Failures are caught and reported without crashing the loop, while pressing q exits cleanly.
![image.png](https://blueprint.hackclub.com/user-attachments/blobs/proxy/eyJfcmFpbHMiOnsiZGF0YSI6MzYwNywicHVyIjoiYmxvYl9pZCJ9fQ==--8471a7cb080fafc09e132cfca9e8b8f00c8e0024/image.png)
  

